DONE

	Implement basic throughput test in google cloud. How far can I push it?

	Seems that we can do around 3 * 1000 * 1000 = 3m packets per-second, @ 256 bytes average packet size.

	We seem to overload around 0.7 gigabytes per-second. This is reasonable enough for now.

	The limit seems to be more packets per-second, rather than bandwidth. Greater throughput can be obtained, with larger packet sizes.

	Upgrade client to use atomics.

	Extend packets sent to proxy to include a uint64 sequence number in the first 8 bytes.

	Track packet loss via packet buffer, and print it out.

TODO

	Now run the client and proxy in the cloud and verify we get zero packet loss at a baseline load.

	---------------

















-------------------------

	Create a bootstrap script for the client, so it can be setup as a mig and scaled up/down easily.

	Explore alternative ways to receive and send packets, eg. sendmmsg, recvmmsg in Linux, to potentially reduce overhead.
