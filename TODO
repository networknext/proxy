DONE

	Create a new test account in dev, eg. "proxy-test".

	Generate a keypair and assign it to the account.

	Put the keypair in the proxy examples.

		Welcome to Network Next!

		This is your public key:

		    87imaWGyq+J7p3DpwJwstjHGrPQBEl3eCQmsEYWpN8nmi2lCfWD9VA==

		This is your private key:

		    87imaWGyq+JSNpzHRsFS1mX4Y5xlHi8IduJDfJOfiTgPEoJYvpbIqHuncOnAnCy2Mcas9AESXd4JCawRhak3yeaLaUJ9YP1U

TODO

	--------------

	Setup this account to force network next, but only for 10% of sessions.

	This will line up with the intended us of 1 in 10 sessions being accelerated going through the proxy.

	--------------

	Setup a dev relay in google cloud and enable it in the "proxy-test" account.

	--------------

	Run the proxy in google cloud against dev5 backend. 

	Verify it inits properly.

	--------------

	Run 2000 clients, with only 10% accelerated.

	Verify that we can get through the proxy to the server without additional latency, jitter or PL.

	--------------

	If additional latency PL occurs, due to next, verify that we can still do the 2000 clients without using next.

	If this is the case, the bottleneck is the network next socket and thread, and we need to split network next server across n sockets (eg. prefix all packets with session id and modulo to n network next server threads).

	--------------

	If we can run 2000 clients with 200 accelerated, we are done. The proxy compenent is verified load tested.

	--------------

	Load test in GCore, with 2000 clients direct, and 2000 clients next.

	Can we handle it? It's likely that the GCore bare metal will be much more performant than the Google cloud VMs.

	--------------

	Add a func test for sdk5 so we don't get 100% PL reported when the client isn't upgraded.

	--------------

	Apply the same fix to sdk4. Add a func test there too.

	--------------
