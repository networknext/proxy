DONE

	Extend proxy.cpp to read in environment variables for configuration.

	Setup a proxy.env that will run in google cloud, and actually init with the dev5 backend.

	Extend client.cpp so it can create n clients

	Put a mutex in each client thread_data_t, then once per-update, grab the mutex and stash all required stats into a mutex protected copy of stats (sent, received, lost, latency, jitter, packet_loss).

	Then create a stats thread in client.cpp, once every 5 seconds, sum up all stats (sent, received, lost), and take the max of (latency, jitter and pl).

	Print this out.

	Now we can see for n network next enabled clients, if they are running properly, without packet loss or latency/jitter added due to the proxy.

	Test locally with 1 client, is it working?

	No. Packets are lost with the next route, and the direct route even though packets are coming through, gives 100% PL in next client stats.

	What happened?

	Test proxy locally and debug why we're seeing strange issues.

	Works fine with passthrough and with direct packets.

	With a next route, it looks like client -> server packets get to the relay, but the relay is not seeing any server -> client packets.

	What's going on with the broken server -> client packets?

	The first thing to test is whether the server is actually getting the client -> server (proxy) -> real server packets or not.

	It could be that the next server is not getting the server -> client packets, so it's not responding at all.

	It could be that the proxy next server is not forwarding server to client packets through the relay properly.

	But most likely, I think the proxy next server is just not getting the packets from the relay....

	Add logs to check if the proxy next server is getting next client to server packets or not.

	The next proxy server is getting the client to server packet.

	There is definitely some weird thing where NEAR PINGS go to the relay very fast for 10 seconds, when it first goes onto next. Why is this?

	Looks almost like high frequency pings code is broken.

	Fixed. The ref backends were oscillating the high frequency ping on/off.

	Add logs to see if the real server is getting packets from the proxy.

	The server is not getting packets from the proxy.

TODO

	This means that the error is the proxy is not processing CLIENT_TO_SERVER packets properly, and forwarding them to the server.

	Add logs to debug what's going on...
	

	--------------






































	--------------

	Create a new test account, eg. "proxy-test".

	Setup this account to force network next, but only for 10% of sessions.

	This will line up with the intended us of 1 in 10 sessions being accelerated going through the proxy.

	--------------

	Setup a dev relay in google cloud and enable it in the "proxy-test" account.

	--------------

	Run the proxy in google cloud against dev5 backend. 

	Verify it inits properly.

	--------------

	Run 2000 clients, with only 10% accelerated.

	Verify that we can get through the proxy to the server without additional latency, jitter or PL.

	--------------

	If additional latency PL occurs, due to next, verify that we can still do the 2000 clients without using next.

	If this is the case, the bottleneck is the network next socket and thread, and we need to split network next server across n sockets (eg. prefix all packets with session id and modulo to n network next server threads).

	--------------

	If we can run 2000 clients with 200 accelerated, we are done. The proxy compenent is verified load tested.

	--------------

	Load test in GCore, with 2000 clients direct, and 2000 clients next.

	Can we handle it? It's likely that the GCore bare metal will be much more performant than the Google cloud VMs.

	--------------

	Add a func test for sdk5 so we don't get 100% PL reported when the client isn't upgraded.

	--------------

	Apply the same fix to sdk4. Add a func test there too.

	--------------
