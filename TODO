DONE

	Extend proxy.cpp to read in environment variables for configuration.

	Setup a proxy.env that will run in google cloud, and actually init with the dev5 backend.

TODO

	--------------

	Extend client.cpp so it can create n clients

	--------------

	Create a new test account, eg. "proxy-test".

	Setup this account to force network next, but only for 10% of sessions.

	This will line up with the intended us of 1 in 10 sessions being accelerated going through the proxy.

	--------------

	Setup a dev relay in google cloud and enable it in the "proxy-test" account.

	--------------

	Run the proxy in google cloud against dev5 backend. 

	Verify it inits properly.

	--------------

	Run 2000 clients, with only 10% accelerated.

	Verify that we can get through the proxy to the server without additional latency, jitter or PL.

	--------------

	If additional latency PL occurs, due to next, verify that we can still do the 2000 clients without using next.

	If this is the case, the bottleneck is the network next socket and thread, and we need to split network next server across n sockets (eg. prefix all packets with session id and modulo to n network next server threads).

	--------------

	If we can run 2000 clients with 200 accelerated, we are done. The proxy compenent is completed.

	--------------

	Load test in GCore, with 2000 clients direct, and 2000 clients next.

	Can we handle it? It's likely that the GCore bare metal will be much more performant than the Google cloud VMs.

	--------------


























	--------------

	Add a func test for sdk5 so we don't get 100% PL reported when the client isn't upgraded.

	--------------

	Apply the same fix to sdk4. Add a func test there too.

	--------------













	--------------

	Load test that we can hit 2000 clients with the proxy actually upgrading each connected client.

	This will require some load test client MIG where we can scale out n clients per-machine, and scale up.

	--------------

	If we can't hit the 2000 clients with next active, we'll need to split up into multiple network next threads.

	This requires prefixing the network next packets with the session id, which is an extensive change. Try to avoid if possible.

	--------------

	Load test in bare metal on GCore

	--------------
